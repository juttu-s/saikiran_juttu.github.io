<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Structure From Motion | Hugo Academic CV Theme</title>
    <link>http://localhost:1313/tags/structure-from-motion/</link>
      <atom:link href="http://localhost:1313/tags/structure-from-motion/index.xml" rel="self" type="application/rss+xml" />
    <description>Structure From Motion</description>
    <generator>Hugo Blox Builder (https://hugoblox.com)</generator><language>en-us</language><lastBuildDate>Thu, 07 Nov 2024 00:00:00 +0000</lastBuildDate>
    <image>
      <url>http://localhost:1313/media/icon_hu7729264130191091259.png</url>
      <title>Structure From Motion</title>
      <link>http://localhost:1313/tags/structure-from-motion/</link>
    </image>
    
    <item>
      <title>Sparse 3D Reconstruction and Bundle Adjustment</title>
      <link>http://localhost:1313/project/sparse-reconstruction/</link>
      <pubDate>Thu, 07 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/project/sparse-reconstruction/</guid>
      <description>&lt;p&gt;This project implements a full Structure from Motion (SfM) pipeline on a &lt;strong&gt;Buddha statue&lt;/strong&gt; using a sequence of &lt;strong&gt;24 grayscale images&lt;/strong&gt;. It combines feature detection, epipolar geometry, camera pose recovery, triangulation, and bundle adjustment.&lt;/p&gt;
&lt;hr&gt;
&lt;h3 id=&#34;dataset&#34;&gt;Dataset&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;24 images of a wooden Buddha statue captured at different angles&lt;/li&gt;
&lt;li&gt;Enhanced using &lt;strong&gt;CLAHE (Contrast Limited Adaptive Histogram Equalization)&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Features extracted using &lt;strong&gt;SIFT&lt;/strong&gt; with custom parameters&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;pipeline-overview&#34;&gt;Pipeline Overview&lt;/h3&gt;
&lt;h4 id=&#34;1-image-preprocessing&#34;&gt;1. Image Preprocessing&lt;/h4&gt;
&lt;p&gt;Using CLAHE improves contrast on low-texture surfaces like carved wood.&lt;/p&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;img src=&#34;processed.png&#34; width=&#34;1000&#34;&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h4 id=&#34;2-sift-feature-detection&#34;&gt;2. SIFT Feature Detection&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Applied to all 24 images&lt;/li&gt;
&lt;li&gt;Used &lt;strong&gt;BFMatcher&lt;/strong&gt; with ratio test&lt;/li&gt;
&lt;li&gt;Matches filtered via &lt;strong&gt;RANSAC&lt;/strong&gt; for outlier rejection&lt;/li&gt;
&lt;/ul&gt;
&lt;div style=&#34;text-align: center;&#34;&gt;
&lt;img src=&#34;features.png&#34; width=&#34;1000&#34;&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;h4 id=&#34;3-essential-matrix--pose-recovery&#34;&gt;3. Essential Matrix &amp;amp; Pose Recovery&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Computed Essential matrix using calibrated camera matrix&lt;/li&gt;
&lt;li&gt;Used &lt;code&gt;cv2.recoverPose()&lt;/code&gt; to derive relative rotation and translation between views&lt;/li&gt;
&lt;li&gt;Built a chain of camera poses from image 0 onward&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;4-triangulation&#34;&gt;4. Triangulation&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;3D points computed from pixel correspondences using &lt;code&gt;cv2.triangulatePoints()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;All 3D points stored in homogeneous form&lt;/li&gt;
&lt;li&gt;Colored and visualized using Plotly&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h4 id=&#34;5-bundle-adjustment-with-gtsam&#34;&gt;5. Bundle Adjustment with GTSAM&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Built a factor graph with:
&lt;ul&gt;
&lt;li&gt;Camera pose priors&lt;/li&gt;
&lt;li&gt;Between factors from pose transitions&lt;/li&gt;
&lt;li&gt;Projection factors from 2D-3D matches&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Used &lt;code&gt;Levenberg-MarquardtOptimizer&lt;/code&gt; for refinement&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;results&#34;&gt;Results&lt;/h3&gt;
&lt;h4 id=&#34;initial-3d-trajectory&#34;&gt;Initial 3D Trajectory&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Initial Trajectory&#34; srcset=&#34;
               /project/sparse-reconstruction/Initial_plot_hu12090084634136375331.webp 400w,
               /project/sparse-reconstruction/Initial_plot_hu6971695684859321629.webp 760w,
               /project/sparse-reconstruction/Initial_plot_hu11908849571792030370.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/sparse-reconstruction/Initial_plot_hu12090084634136375331.webp&#34;
               width=&#34;760&#34;
               height=&#34;282&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h4 id=&#34;optimized-3d-trajectory-after-bundle-adjustment&#34;&gt;Optimized 3D Trajectory after Bundle Adjustment&lt;/h4&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;flex justify-center	&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Optimized Trajectory&#34; srcset=&#34;
               /project/sparse-reconstruction/Optimized_plot_hu1365288965832748826.webp 400w,
               /project/sparse-reconstruction/Optimized_plot_hu5432368712792554619.webp 760w,
               /project/sparse-reconstruction/Optimized_plot_hu6617160073620067270.webp 1200w&#34;
               src=&#34;http://localhost:1313/project/sparse-reconstruction/Optimized_plot_hu1365288965832748826.webp&#34;
               width=&#34;760&#34;
               height=&#34;282&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Average reprojection error reduced by ~15%&lt;/li&gt;
&lt;li&gt;Landmark cloud tightened around object geometry&lt;/li&gt;
&lt;li&gt;Rotation drift corrected with global optimization&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;tools--libraries&#34;&gt;Tools &amp;amp; Libraries&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;OpenCV (SIFT, RANSAC, triangulation)&lt;/li&gt;
&lt;li&gt;NumPy, Matplotlib, Plotly&lt;/li&gt;
&lt;li&gt;GTSAM (factor graph + BA)&lt;/li&gt;
&lt;li&gt;Python&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;h3 id=&#34;resources&#34;&gt;Resources&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;ðŸ”— &lt;a href=&#34;https://github.com/juttu-s/Sparse-3D-Reconstruction&#34; target=&#34;_blank&#34; rel=&#34;noopener&#34;&gt;GitHub Repo&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;
&lt;p&gt;This project demonstrates a scalable pipeline for SfM using minimal dependencies. It serves as a foundation for integrating real-time VIO or stereo SLAM on embedded platforms.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
